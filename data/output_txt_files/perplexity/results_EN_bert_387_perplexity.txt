Torch version: 2.5.1
CUDA available: True
CUDA device count: 9
Current CUDA device: 0
CUDA device name: NVIDIA GeForce RTX 2080 Ti
We will use the GPU: NVIDIA GeForce RTX 2080 Ti
Tokenizer loaded successfully!
Preparing validation data...
Max sentence length in validation set: 128
Number of sentences to tokenize: 13439
Number of sentences successfully tokenized: 13439
Found 4 checkpoint files

=== BASELINE METRICS (EPOCH 0 MODEL) ===
Using locally saved epoch 0 model: ../models/bert_checkpoints/random_seed_387/finetuned_bert_387_epoch_0.pt
Epoch 0 model loaded successfully!


Running Baseline (Epoch 0) perplexity calculation...
Baseline (Epoch 0) Loss: 3.3188, Perplexity: 27.63

=== Processing checkpoint: finetuned_bert_387_epoch_1.pt ===
Checkpoint from epoch 1 loaded successfully!


Running Epoch 1 perplexity calculation...
Epoch 1 Loss: 3.2722, Perplexity: 26.37

=== Processing checkpoint: finetuned_bert_387_epoch_2.pt ===
Checkpoint from epoch 2 loaded successfully!


Running Epoch 2 perplexity calculation...
Epoch 2 Loss: 3.2505, Perplexity: 25.80

=== Processing checkpoint: finetuned_bert_387_epoch_3.pt ===
Checkpoint from epoch 3 loaded successfully!


Running Epoch 3 perplexity calculation...
Epoch 3 Loss: 3.2696, Perplexity: 26.30

=== Processing final model ===


Running Final Model perplexity calculation...
Final Model Loss: 3.2696, Perplexity: 26.30
Final model loaded successfully!

Results saved to ../data/output_csv_files/english/perplexity/results_EN_bert_387_perplexity.csv

=== SUMMARY ===
                      checkpoint  epoch  validation_loss  perplexity
0  finetuned_bert_387_epoch_0.pt      0         3.318822   27.627791
1  finetuned_bert_387_epoch_1.pt      1         3.272234   26.370181
2  finetuned_bert_387_epoch_2.pt      2         3.250521   25.803769
3  finetuned_bert_387_epoch_3.pt      3         3.269582   26.300334
4                    final_model  final         3.269582   26.300334

=== PERPLEXITY IMPROVEMENT ===
finetuned_bert_387_epoch_1.pt: 4.55% (improved)
finetuned_bert_387_epoch_2.pt: 6.60% (improved)
finetuned_bert_387_epoch_3.pt: 4.80% (improved)
final_model: 4.80% (improved)
